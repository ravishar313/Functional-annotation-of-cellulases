{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the whole of CAZy\n",
    "import re\n",
    "\n",
    "class CAZy_data:\n",
    "    def __init__(self,filename1,filename2):\n",
    "        self.data,self.acc,self.seq=[],[],[]\n",
    "        with open(filename1,'r',encoding='utf-8') as inpt:\n",
    "            for each in inpt:\n",
    "                self.data.append(each.rstrip().split('$'))\n",
    "                \n",
    "        with open(filename2,'r',encoding='utf-8') as inpt1:\n",
    "            for each1 in inpt1:\n",
    "                if each1.startswith('>'):\n",
    "                    self.acc.append(each1.rstrip())\n",
    "                else:\n",
    "                    self.seq.append(each1.rstrip())\n",
    "            \n",
    "                  \n",
    "    def data_fetch(self,typ,position):\n",
    "        typ_data=[]\n",
    "        if typ=='all':\n",
    "            typ_data=self.data\n",
    "        else:\n",
    "            for each in self.data:\n",
    "                mult=each[position].split(' ')\n",
    "                if len(mult)==1:#### In case typ = EC, Multi EC number and protein with no EC number are ignore.\n",
    "                    if mult[0]==typ:\n",
    "                        typ_data.append(each)\n",
    "        return typ_data\n",
    "    \n",
    "    def EC_GH(self,ec_no,gh_fam):\n",
    "        self.fasta=[]\n",
    "        cazy_ec=self.data_fetch(ec_no,1)\n",
    "        cazy_gh=self.data_fetch(gh_fam,-1)\n",
    "        self.common_data=[[i[0],i[1],i[3],i[4],i[-2],i[-1]] for i in cazy_ec if i in cazy_gh]\n",
    "        rm_prt, rm_prt_fasta=[],[]\n",
    "        for each in range(len(self.common_data)):\n",
    "            t=self.common_data[each]\n",
    "            if self.prtn_filter(t[0]):\n",
    "                all_acc=t[3].split(' ')\n",
    "                if all_acc[0]!='':\n",
    "                    for e_acc in all_acc:\n",
    "                        e_seq=self.seq_fetch(e_acc)\n",
    "                        try:\n",
    "                            create_error=0/len(e_seq) # to remove accession number which doesnt have hits\n",
    "                            self.fasta.append(f'>{e_acc}${t[0]}${t[1]}${t[2]}${t[-2]}${t[-1]}')\n",
    "                            self.fasta.append(e_seq[0])\n",
    "                        except ZeroDivisionError:\n",
    "                            rm_prt_fasta.append(e_acc)\n",
    "            else:\n",
    "                rm_prt.append(t)\n",
    "#         print('Total number of sequences:',len(self.fasta)/2)\n",
    "#         print('Number of removed partial or fragment proteins (CAZy):',len(rm_prt))\n",
    "#         print('Number of removed partial or fragment proteins (Fasta):',len(rm_prt_fasta))\n",
    "        return self.fasta,rm_prt,rm_prt_fasta\n",
    "    def prtn_filter(self,prt_name):\n",
    "        hit=1\n",
    "        if re.search('partial|fragment',prt_name.lower()):\n",
    "            hit-=1\n",
    "        return hit\n",
    "            \n",
    "    def seq_fetch(self,accession):\n",
    "        hits=[]\n",
    "        temp=0\n",
    "        for each in range(len(self.acc)):\n",
    "            if re.search(f'{accession}\\D',self.acc[each]):\n",
    "                temp+=1\n",
    "                \n",
    "                if self.prtn_filter(self.acc[each]): # remove partial| fragment accession numbers from GenBank description\n",
    "                    hits.append(self.seq[each])\n",
    "        if temp>1:\n",
    "            print(f'Multiple hits for {accession}')\n",
    "        elif temp==0:\n",
    "            print(f'No hits for {accession}')\n",
    "        return hits\n",
    "     \n",
    "In_data=CAZy_data('cazy_char_10_6_22.txt','char_gh_23_6_22.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please input the EC number (write all if no preference):3.2.1.4\n",
      "please input the GH family (write all if no preference):GH8\n"
     ]
    }
   ],
   "source": [
    "EC_number= input('please input the EC number (write all if no preference):')\n",
    "GH_family= input('please input the GH family (write all if no preference):')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hits for NP_213966.1\n"
     ]
    }
   ],
   "source": [
    "cazy_acc_seq,rm_cazy,rm_genbank=In_data.EC_GH(EC_number,GH_family) # write all to fetch all the EC number or all the GH family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting sequence and accession IDs\n",
    "acc,seq=[],[]\n",
    "for ii in cazy_acc_seq:\n",
    "    if ii.startswith('>'):\n",
    "        acc.append(ii.rstrip())\n",
    "    else:\n",
    "        seq.append(ii.rstrip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary with only the reqiuired information with the accession ID\n",
    "acc_seq={}\n",
    "for i in range(len(acc)):\n",
    "    accc=acc[i].split('$')\n",
    "    acc_no=accc[0]\n",
    "    x='>'+acc_no[1:]+'&'+accc[2]+'&'+accc[4]+'&'+accc[5]\n",
    "    acc_seq[x] = seq[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the file with the required info\n",
    "filename='EC'+EC_number.split('.')[3]+'_'+GH_family+'.fasta'\n",
    "y=len(seq)\n",
    "with open(filename,'w',encoding='utf-8') as otp:\n",
    "    for i in acc_seq.keys():\n",
    "        seq=acc_seq.get(i)\n",
    "        otp.write(i+'\\n'+seq+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform CD-hit step\n",
    "identities=[0.9,0.8,0.7,0.6,0.5,0.4]\n",
    "short_word=[5,5,5,4,3,2]\n",
    "cd_hit_files=[]\n",
    "for i in range(5):\n",
    "    y=str(int(identities[i]*100))\n",
    "    x='EC'+EC_number.split('.')[3]+'_'+GH_family+'_'+ y +'.fasta'\n",
    "    cd_hit_files.append(x)\n",
    "    cmd='cd-hit -i '+ filename + ' -o EC'+EC_number.split('.')[3]+'_'+GH_family+'_'+ y +'.fasta' + ' -c ' + str(identities[i]) +' -n ' + str(short_word[i])\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to find outliers using IQR\n",
    "\n",
    "def find_outliers_IQR(df):\n",
    "    q1=df.quantile(0.25) #finding the first and 3rd quatrile\n",
    "    q3=df.quantile(0.75)\n",
    "    IQR=q3-q1 #finding the interquatrile range\n",
    "    outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))] #finding outliers\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file with no outliers is successfully saved\n",
      "multifasta file with no length outliers is successfully saved\n",
      "csv file with no outliers is successfully saved\n",
      "multifasta file with no length outliers is successfully saved\n",
      "csv file with no outliers is successfully saved\n",
      "multifasta file with no length outliers is successfully saved\n",
      "csv file with no outliers is successfully saved\n",
      "multifasta file with no length outliers is successfully saved\n",
      "csv file with no outliers is successfully saved\n",
      "multifasta file with no length outliers is successfully saved\n",
      "csv file with no outliers is successfully saved\n",
      "multifasta file with no length outliers is successfully saved\n"
     ]
    }
   ],
   "source": [
    "#cd_hit_files=['EC4_GH8_40.fasta','EC4_GH8_50.fasta', 'EC4_GH8_60.fasta', 'EC4_GH8_70.fasta', 'EC4_GH8_80.fasta', 'EC4_GH8_90.fasta']\n",
    "for_hmm=[]\n",
    "for file in cd_hit_files:\n",
    "    acc,seq=[],[]\n",
    "    with open(file,'r',encoding='utf-8') as fasta_file:\n",
    "        #print(file)\n",
    "        for ii in fasta_file:\n",
    "            if ii.startswith('>'):\n",
    "                acc.append(ii.rstrip())\n",
    "            else:\n",
    "                seq.append(ii.rstrip()) \n",
    "        acc_seq={}\n",
    "        for i in range(len(acc)):\n",
    "            accc=acc[i].split('$')\n",
    "            acc_no=accc[0]\n",
    "            acc_seq[acc_no[1:]] = seq[i]\n",
    "        #print(acc_seq)\n",
    "        acc_vs_seq=pd.DataFrame.from_dict(acc_seq, orient = 'index')\n",
    "        acc_vs_seq.set_axis(['Sequence'], axis=1 , inplace=True)\n",
    "        acc_vs_seq['Length']=np.nan\n",
    "        for i in range(len(acc)): \n",
    "            acc_vs_seq.iloc[i,1]=int(len(acc_vs_seq.iloc[i,0]))\n",
    "        filename1=file.split('.')[0]+'.csv'\n",
    "        acc_vs_seq.to_csv(filename1)\n",
    "        #finding out the outliers and removing them step follows\n",
    "        acc_vs_seq=pd.read_csv(filename1) #read the csv file containing the length of each sequence as well, obtained from Get_EC_GH.ipynb\n",
    "        acc_vs_seq.rename( columns={'Unnamed: 0':'ID'}, inplace=True ) #rename the unnamed column as ID\n",
    "        x=list(find_outliers_IQR(acc_vs_seq['Length'])) #finding length outliers, saving them to list\n",
    "        acc_vs_seq=acc_vs_seq[acc_vs_seq.Length.isin(x) == False] #removing the outlier. if the length is not in hte outlier list (x), they are taken\n",
    "        acc_vs_seq.reset_index(inplace = True, drop = True) #resetting the index, as after dropping there are missing index values\n",
    "        filename2= file.split('.')[0]+'_no_outliers.csv' #saving the updated csv file\n",
    "        acc_vs_seq.to_csv(filename2)\n",
    "        print('csv file with no outliers is successfully saved')\n",
    "        #saving the sequences to multifasta\n",
    "        xx=(acc_vs_seq.ID.count())\n",
    "        filename3=file.split('.')[0]+'_no_outliers.fasta'\n",
    "        for_hmm.append(filename3)\n",
    "        with open(filename3,'w',encoding='utf-8') as otp:\n",
    "            for i in range(xx):\n",
    "                acc_id=acc_vs_seq.iloc[i,0]\n",
    "                seq=acc_vs_seq.iloc[i,1]\n",
    "                otp.write('>'+acc_id+'\\n'+seq+'\\n')\n",
    "        print('multifasta file with no length outliers is successfully saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC4_GH8_40_no_outliers.fasta\n",
      "EC4_GH8_50_no_outliers.fasta\n",
      "EC4_GH8_60_no_outliers.fasta\n",
      "EC4_GH8_70_no_outliers.fasta\n",
      "EC4_GH8_80_no_outliers.fasta\n",
      "EC4_GH8_90_no_outliers.fasta\n"
     ]
    }
   ],
   "source": [
    "#making hmm for each cutoff\n",
    "hmm_files=[]\n",
    "for fas_for_hmm in for_hmm:\n",
    "    print(fas_for_hmm)\n",
    "    cmd_aln='mafft '+ fas_for_hmm + ' > ' +fas_for_hmm.split('.')[0]+'.aln'\n",
    "    os.system(cmd_aln)\n",
    "    print('alignment done for '+ fas_for_hmm)\n",
    "    cmd_hmm='hmmbuild '+ fas_for_hmm.split('.')[0]+'.hmm ' + fas_for_hmm.split('.')[0]+'.aln'\n",
    "    os.system(cmd_hmm)\n",
    "    hmm_files.append(fas_for_hmm.split('.')[0]+'.hmm ')\n",
    "    print('hmm build for '+ fas_for_hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_file=input('file you would like to evaluate the HMMs against:')\n",
    "#evaluation of HMMs\n",
    "eval_files=[]\n",
    "for hmm_file in hmm_files:\n",
    "    xx=hmm_file.split('.')[0]+'_vs_'+search_file.split('.')[0]+'.txt'\n",
    "    eval_files.append(xx)\n",
    "    cmd_search='hmmsearch --noali --domtblout ' + hmm_file.split('.')[0]+'_vs_'+search_file.split('.')[0]+'.txt '+ hmm_file+search_file\n",
    "    os.system(cmd_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravis\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ROC files saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#eval_files=['EC4_GH8_40_no_outliers_vs_all_GH8.txt']\n",
    "#making ROC curves\n",
    "for eval_file in eval_files:\n",
    "    use,no_use=[],[]\n",
    "    with open(eval_file,'r',encoding='utf-8') as otp:\n",
    "        for ii in otp:\n",
    "            if ii.startswith('#'):\n",
    "                #print(no_use)\n",
    "                no_use.append(ii)\n",
    "            else:\n",
    "                #print(use)\n",
    "                use.append(ii) \n",
    "    xx=len(use)\n",
    "    with open('test_del.txt','w',encoding='utf-8') as otp:\n",
    "        for i in range(xx):\n",
    "            info=use[i]\n",
    "            otp.write(info)\n",
    "    import re\n",
    "    new_data=[]\n",
    "    for i in use:\n",
    "        j=re.split('\\s+',i.strip())\n",
    "        new_data.append(j)\n",
    "    df2=pd.DataFrame(new_data)\n",
    "    df3=df2[[0,13,15,16,17,18,22]]\n",
    "    df3.columns=['ID','Score','hmm_start','hmm_end','ali_start','ali_end','description']\n",
    "    x=df3['description'].tolist()\n",
    "    y=df3['ID'].tolist()\n",
    "    filename4=eval_file.split('.')[0]+'_raw.csv'\n",
    "    df3.to_csv(filename4)\n",
    "    IDs=[]\n",
    "    for i in range(len(x)):\n",
    "        if x[i].startswith('-'):\n",
    "            z=y[i]\n",
    "            IDs.append(z)\n",
    "        else:\n",
    "            z=y[i]+x[i]\n",
    "            IDs.append(z)\n",
    "    df3['IDs']=IDs\n",
    "    df3=df3.drop(['ID','description'], axis=1)\n",
    "    df3.Score = df3.Score.astype(float)\n",
    "    df3=df3.sort_values(by=['Score'], ascending=False)\n",
    "    score=df3['Score'].to_list()\n",
    "    data=df3['IDs'].to_list()\n",
    "    TP,TN,FP,FN=[],[],[],[]\n",
    "    for threshold in score:\n",
    "        #print('threshold is ' + threshold)\n",
    "        tp,fp=0,0\n",
    "        fn,tn=0,0\n",
    "        #print('loop1')\n",
    "        for current_score in score:\n",
    "            #print(current_score)\n",
    "            #tp,fp=0,0\n",
    "            #print('loop2')\n",
    "            if float(current_score)>=float(threshold):\n",
    "                #tp,fp=0,0\n",
    "                #print('current score '+ current_score + ' is higher than threshold '+ threshold)\n",
    "                #print('loop3')\n",
    "                if EC_number in data[score.index(current_score)]:\n",
    "                    #print('TP + 1')\n",
    "                    tp=tp+1\n",
    "                    #print(tp)\n",
    "                    #print('loop4')\n",
    "                else: \n",
    "                    #print('FP+1')\n",
    "                    fp=fp+1\n",
    "            else:\n",
    "                #print('current score '+ current_score + ' is lower than threshold '+ threshold)\n",
    "                if EC_number in data[score.index(current_score)]:\n",
    "                    #print('FN + 1')\n",
    "                    fn=fn+1\n",
    "                else: \n",
    "                    #print('TN +1')\n",
    "                    tn=tn+1\n",
    "        TP.append(tp)\n",
    "        FP.append(fp)\n",
    "        FN.append(fn)\n",
    "        TN.append(tn)\n",
    "    #print(TP,TN,FP,FN)\n",
    "    dff=pd.DataFrame()\n",
    "    dff['Threshold']=score\n",
    "    dff['TP']=TP\n",
    "    dff['TN']=TN\n",
    "    dff['FP']=FP\n",
    "    dff['FN']=FN\n",
    "    dff['FPR']=np.nan\n",
    "    dff['TPR']=np.nan\n",
    "    index=dff.index\n",
    "    FPR,TPR=[],[]\n",
    "    for i in index:\n",
    "        tp=dff.iloc[i,1]\n",
    "        tn=dff.iloc[i,2]\n",
    "        fp=dff.iloc[i,3]\n",
    "        fn=dff.iloc[i,4]\n",
    "        fpr=fp/(fp+tn)\n",
    "        tpr=tp/(tp+fn)\n",
    "        FPR.append(fpr)\n",
    "        TPR.append(tpr)\n",
    "    dff['FPR']=FPR\n",
    "    dff['TPR']=TPR\n",
    "    filename5=eval_file.split('.')[0]+'_ROC.csv'\n",
    "    dff.to_csv(filename5)\n",
    "    plt.clf()\n",
    "    plt.scatter(dff.FPR, dff.TPR, c =\"blue\", s=10)\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    filename6=filename5.split('.')[0]+'.png'\n",
    "    plt.savefig(filename6, dpi=300)\n",
    "    \n",
    "print('all ROC files saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
